# %% [markdown]
# # 基于元学习的跨被试前额叶EEG风险感知预测
# 环境要求：Python 3.9+, PyTorch 1.13+, MNE 1.4+

# %% [code] 安装依赖
!pip install mne torchmeta pytorch-lightning captum scikit-learn umap-learn

# %% [code] 导入库
import os
import numpy as np
import pandas as pd
import mne
import torch
import torch.nn as nn
import torch.optim as optim
from torchmeta.utils.gradient_based import reptile_update
import torchmeta as tm
import pytorch_lightning as pl
from pytorch_lightning.callbacks import EarlyStopping
from captum.attr import IntegratedGradients
from sklearn.model_selection import LeaveOneGroupOut
from sklearn.metrics import roc_auc_score, f1_score
from umap import UMAP
import matplotlib.pyplot as plt
from tqdm import tqdm

# %% [code] 配置参数
class Config:
    # 数据参数
    seed_vig_path = "./data/SEED-VIG"
    target_data_path = "./data/driving_risk"
    fs = 250  # 降采样后的采样率
    bands = {'delta': (1, 4), 'theta': (4, 8), 'alpha': (8, 14), 
             'beta': (14, 31), 'gamma': (31, 50)}
    
    # 模型参数
    input_channels = 5  # 5个频带
    hidden_dim = 32
    num_classes = 2
    
    # 训练参数
    pretrain_epochs = 20
    meta_epochs = 100
    n_way = 1  # 每次任务类别数
    k_shot = 5  # 支持集样本数
    meta_batch_size = 4  # 每次元更新的任务数
    lr = 1e-4
    
    # 硬件优化
    batch_size = 32
    precision = '16-mixed'  # 混合精度训练
    accelerator = 'auto'
    
config = Config()

# %% [code] 数据预处理函数
class EEGPreprocessor:
    def __init__(self, config):
        self.config = config
        self.ch_names = ['FP1']  # 单通道前额叶
        
    def process_seed_vig(self, file_path):
        """处理SEED-VIG数据集用于预训练"""
        # 加载数据 (假设为fif格式)
        raw = mne.io.read_raw_fif(file_path, preload=True)
        
        # 预处理流程
        raw = self._preprocess_raw(raw)
        
        # 提取特征
        features, labels = self.extract_features(raw)
        return features, labels
    
    def process_driving_data(self, subject_id, scenario_id):
        """处理目标域驾驶风险数据"""
        # 加载数据 (假设每个被试每个场景单独文件)
        file_path = f"{config.target_data_path}/sub_{subject_id}_scen_{scenario_id}.fif"
        raw = mne.io.read_raw_fif(file_path, preload=True)
        
        # 预处理流程
        raw = self._preprocess_raw(raw)
        
        # 提取特征
        features = self.extract_features(raw, is_target=True)
        return features
    
    def _preprocess_raw(self, raw):
        """通用预处理流程"""
        # 降采样
        if raw.info['sfreq'] > config.fs:
            raw.resample(config.fs, npad='auto')
        
        # 带通滤波
        raw.filter(1, 50, fir_design='firwin')
        
        # 选择前额叶通道
        picks = mne.pick_channels(raw.ch_names, include=self.ch_names)
        raw.pick_channels([raw.ch_names[i] for i in picks])
        return raw
    
    def extract_features(self, raw, is_target=False):
        """提取5频带差分熵特征"""
        # 创建固定长度epoch
        epochs = mne.make_fixed_length_epochs(raw, duration=2.0, overlap=1.0)
        
        # 计算功率谱密度
        psd, freqs = mne.time_frequency.psd_multitaper(
            epochs, fmin=1, fmax=50, bandwidth=1)
        
        # 计算频带平均PSD
        band_psd = []
        for band, (fmin, fmax) in config.bands.items():
            freq_mask = (freqs >= fmin) & (freqs <= fmax)
            band_psd.append(psd[:, :, freq_mask].mean(axis=-1))
        
        # 差分熵特征 = log(PSD)
        de_features = np.log(np.array(band_psd).transpose(1, 2, 0))
        
        # 对于目标数据，返回每个epoch的特征
        if is_target:
            return de_features.squeeze(1)  # [n_epochs, 5]
        
        # 对于SEED-VIG，返回特征和标签（示例）
        # 实际中需要加载真实标签
        labels = np.random.randint(0, 3, len(de_features))  # 示例：警觉度标签
        return de_features.squeeze(1), labels

# %% [code] 数据增强类
class EEGAugmentor:
    def __init__(self, noise_level=0.05):
        self.noise_level = noise_level
        
    def augment(self, features):
        """应用多种数据增强"""
        # 随机选择增强方式
        augment_type = np.random.choice(['noise', 'warp', 'mask'])
        
        if augment_type == 'noise':
            return self.add_gaussian_noise(features)
        elif augment_type == 'warp':
            return self.time_warp(features)
        else:
            return self.freq_band_mask(features)
    
    def add_gaussian_noise(self, features):
        noise = np.random.normal(0, self.noise_level, features.shape)
        return features + noise
    
    def time_warp(self, features):
        warp_factor = np.random.uniform(0.8, 1.2)
        warped = np.zeros_like(features)
        for i in range(features.shape[1]):  # 每个频带
            warped[:, i] = np.interp(
                np.linspace(0, features.shape[0]-1, int(features.shape[0]*warp_factor)),
                np.arange(features.shape[0]),
                features[:, i]
            )[:features.shape[0]]
        return warped
    
    def freq_band_mask(self, features):
        mask = np.random.binomial(1, 0.8, (features.shape[1],))
        return features * mask

# %% [code] 元学习模型定义
class MetaFPNet(tm.Module):
    def __init__(self, in_channels, hidden_dim, num_classes):
        super().__init__()
        # 时频特征提取器 (参数量<5K)
        self.feature_extractor = nn.Sequential(
            nn.Conv1d(in_channels, 16, kernel_size=5, padding=2),
            nn.BatchNorm1d(16),
            nn.ELU(),
            nn.Conv1d(16, hidden_dim, kernel_size=3, stride=2),
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten()
        )
        
        # 元自适应分类器
        self.classifier = tm.Linear(hidden_dim, num_classes)
        
        # 神经科学注意力（频带权重）
        self.band_attn = nn.Parameter(torch.tensor([0.1, 0.2, 0.3, 0.2, 0.2]))
    
    def forward(self, x, params=None):
        # 频带注意力加权
        x = x * self.band_attn.unsqueeze(0).unsqueeze(-1)
        
        # 特征提取
        x = self.feature_extractor(x)
        
        # 元学习分类
        return self.classifier(x, params=self.get_subdict(params, 'classifier'))

# %% [code] 元学习训练模块
class MetaLearner(pl.LightningModule):
    def __init__(self, model, config):
        super().__init__()
        self.model = model
        self.config = config
        self.loss_fn = nn.CrossEntropyLoss()
        
        # 神经科学正则化权重
        self.reg_weights = {
            'rrc': 0.3,  # 风险响应约束
            'contrast': 0.2  # 场景对比
        }
    
    def training_step(self, batch, batch_idx):
        # 元学习批处理：多个任务
        task_losses = []
        for task_batch in batch:
            # 每个任务包含支持集和查询集
            support_data, support_labels = task_batch['support']
            query_data, query_labels = task_batch['query']
            
            # 克隆模型用于任务适应
            learner = self.model.clone()
            
            # 在支持集上快速适应
            support_outputs = learner(support_data)
            support_loss = self.loss_fn(support_outputs, support_labels)
            learner.adapt(support_loss)
            
            # 查询集评估
            query_outputs = learner(query_data)
            query_loss = self.loss_fn(query_outputs, query_labels)
            
            # 应用神经科学正则化
            features = learner.feature_extractor(query_data)
            reg_loss = self._neuroscience_regularization(features, query_labels)
            
            task_loss = query_loss + reg_loss
            task_losses.append(task_loss)
        
        # 元更新
        meta_loss = torch.stack(task_losses).mean()
        self.log('train_meta_loss', meta_loss)
        return meta_loss
    
    def _neuroscience_regularization(self, features, labels):
        """神经科学启发的正则化项"""
        # 1. 风险响应约束（高风险样本激活更强）
        high_risk_mask = (labels == 1)
        if torch.sum(high_risk_mask) > 0:
            high_risk_act = features[high_risk_mask].mean()
            low_risk_act = features[~high_risk_mask].mean()
            rrc_loss = torch.relu(0.3 - (high_risk_act - low_risk_act))
        else:
            rrc_loss = torch.tensor(0.0)
        
        # 2. 场景对比学习（需要场景标签）
        # 实际实现中需要获取场景信息
        contrast_loss = torch.tensor(0.0)
        
        total_reg = self.reg_weights['rrc'] * rrc_loss + \
                    self.reg_weights['contrast'] * contrast_loss
        return total_reg
    
    def configure_optimizers(self):
        return optim.AdamW(self.parameters(), lr=self.config.lr)

# %% [code] 数据加载器
def create_meta_learning_dataloader(data, labels, subject_ids, k_shot=5, n_query=3):
    """
    为元学习创建任务数据加载器
    每个任务对应一个被试
    """
    unique_subjects = np.unique(subject_ids)
    tasks = []
    
    for subj_id in unique_subjects:
        # 获取当前被试的所有数据
        subj_mask = (subject_ids == subj_id)
        subj_data = data[subj_mask]
        subj_labels = labels[subj_mask]
        
        # 随机选择支持集和查询集
        n_samples = len(subj_data)
        indices = np.random.permutation(n_samples)
        
        support_idx = indices[:k_shot]
        query_idx = indices[k_shot:k_shot+n_query]
        
        # 转换为张量
        support_data = torch.tensor(subj_data[support_idx], dtype=torch.float32)
        support_labels = torch.tensor(subj_labels[support_idx], dtype=torch.long)
        query_data = torch.tensor(subj_data[query_idx], dtype=torch.float32)
        query_labels = torch.tensor(subj_labels[query_idx], dtype=torch.long)
        
        tasks.append({
            'support': (support_data, support_labels),
            'query': (query_data, query_labels)
        })
    
    return tasks

# %% [code] 模型训练流程
def train_pipeline(config):
    # 1. 初始化组件
    preprocessor = EEGPreprocessor(config)
    augmentor = EEGAugmentor()
    
    # 2. 加载并预处理SEED-VIG数据
    print("Processing SEED-VIG data for pretraining...")
    seed_vig_data, seed_vig_labels = [], []
    for file in tqdm(os.listdir(config.seed_vig_path)):
        if file.endswith('.fif'):
            data, labels = preprocessor.process_seed_vig(
                os.path.join(config.seed_vig_path, file))
            seed_vig_data.append(data)
            seed_vig_labels.append(labels)
    
    seed_vig_data = np.concatenate(seed_vig_data)
    seed_vig_labels = np.concatenate(seed_vig_labels)
    
    # 3. 加载目标域数据
    print("Processing driving risk data...")
    risk_data, risk_labels, subject_ids = [], [], []
    for subj_id in range(1, 65):  # 64名被试
        for scenario_id in range(1, 9):  # 8个场景
            # 实际中需要加载真实问卷得分
            risk_score = np.random.rand()  # 示例随机得分
            
            # 处理EEG数据
            features = preprocessor.process_driving_data(subj_id, scenario_id)
            
            # 应用数据增强
            if config.use_augmentation:
                features = augmentor.augment(features)
            
            # 添加数据
            risk_data.append(features)
            risk_labels.append((risk_score > 0.5).astype(int))  # 二值化
            subject_ids.append(subj_id)
    
    risk_data = np.concatenate(risk_data)
    risk_labels = np.array(risk_labels)
    subject_ids = np.array(subject_ids)
    
    # 4. 创建元学习数据加载器
    print("Creating meta-learning tasks...")
    meta_tasks = create_meta_learning_dataloader(
        risk_data, risk_labels, subject_ids, 
        k_shot=config.k_shot, n_query=3)
    
    # 5. 初始化模型
    model = MetaFPNet(config.input_channels, config.hidden_dim, config.num_classes)
    
    # 6. 预训练阶段（SEED-VIG）
    print("Starting pretraining on SEED-VIG...")
    pretrainer = pl.Trainer(
        max_epochs=config.pretrain_epochs,
        accelerator=config.accelerator,
        precision=config.precision,
        callbacks=[EarlyStopping(monitor='val_loss', patience=3)]
    )
    # 实际中需要实现DataModule
    # pretrainer.fit(model, seed_vig_dataloader)
    
    # 7. 元学习微调
    print("Starting meta-learning fine-tuning...")
    meta_learner = MetaLearner(model, config)
    meta_trainer = pl.Trainer(
        max_epochs=config.meta_epochs,
        accelerator=config.accelerator,
        precision=config.precision,
        gradient_clip_val=0.5
    )
    # 实际中需要包装任务数据
    # meta_trainer.fit(meta_learner, meta_task_loader)
    
    print("Training complete! Saving model...")
    torch.save(model.state_dict(), "meta_fpnet_final.pth")
    return model

# %% [code] 评估与可视化
def evaluate_model(model, test_data, test_labels, subject_ids):
    """跨被试留一验证评估"""
    logo = LeaveOneGroupOut()
    all_preds, all_targets = [], []
    
    for train_idx, test_idx in logo.split(test_data, test_labels, subject_ids):
        # 获取训练测试数据
        X_train, X_test = test_data[train_idx], test_data[test_idx]
        y_train, y_test = test_labels[train_idx], test_labels[test_idx]
        
        # 快速适应当前被试
        adapted_model = model.clone()
        optimizer = optim.SGD(adapted_model.parameters(), lr=0.01)
        
        # 快速适应（少量步骤）
        for _ in range(5):
            outputs = adapted_model(X_train)
            loss = nn.CrossEntropyLoss()(outputs, y_train)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
        
        # 在测试集上评估
        with torch.no_grad():
            test_outputs = adapted_model(X_test)
            preds = torch.softmax(test_outputs, dim=1)[:, 1]
        
        all_preds.extend(preds.cpu().numpy())
        all_targets.extend(y_test.cpu().numpy())
    
    # 计算指标
    auc = roc_auc_score(all_targets, all_preds)
    f1 = f1_score(all_targets, (np.array(all_preds) > 0.5).astype(int))
    print(f"Cross-subject AUC: {auc:.4f}, F1: {f1:.4f}")
    return auc, f1

def visualize_band_importance(model, sample_data):
    """可视化频带重要性"""
    ig = IntegratedGradients(model)
    
    # 计算归因
    attributions = ig.attribute(
        sample_data, 
        target=1,  # 高风险类别
        n_steps=50
    )
    
    # 计算频带平均重要性
    band_importance = attributions.mean(dim=(0, 2)).detach().cpu().numpy()
    
    # 绘图
    plt.figure(figsize=(10, 6))
    bands = list(config.bands.keys())
    plt.bar(bands, band_importance)
    plt.title("EEG Band Importance for Risk Prediction")
    plt.ylabel("Attribution Score")
    plt.savefig("band_importance.png")
    plt.show()

def visualize_feature_space(model, data, labels, subject_ids):
    """可视化特征空间"""
    # 提取特征
    features = []
    with torch.no_grad():
        for i in range(0, len(data), config.batch_size):
            batch = data[i:i+config.batch_size]
            feat = model.feature_extractor(batch).cpu().numpy()
            features.append(feat)
    
    features = np.concatenate(features)
    
    # UMAP降维
    reducer = UMAP(n_components=2, random_state=42)
    embeddings = reducer.fit_transform(features)
    
    # 按风险级别绘图
    plt.figure(figsize=(12, 8))
    plt.scatter(
        embeddings[labels==0, 0], embeddings[labels==0, 1],
        c='blue', alpha=0.5, label='Low Risk'
    )
    plt.scatter(
        embeddings[labels==1, 0], embeddings[labels==1, 1],
        c='red', alpha=0.5, label='High Risk'
    )
    plt.title("EEG Feature Space Visualization")
    plt.legend()
    plt.savefig("feature_space.png")
    plt.show()

# %% [code] 主执行流程
if __name__ == "__main__":
    # 训练模型
    trained_model = train_pipeline(config)
    
    # 加载测试数据（实际中需要实现）
    test_data, test_labels, test_subjects = None, None, None
    
    # 评估模型
    evaluate_model(trained_model, test_data, test_labels, test_subjects)
    
    # 可视化分析
    sample_data = torch.tensor(test_data[:32], dtype=torch.float32)
    visualize_band_importance(trained_model, sample_data)
    visualize_feature_space(trained_model, test_data, test_labels, test_subjects)
    
    print("All tasks completed!")
