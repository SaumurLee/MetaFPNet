# %% [markdown]
# # 基于元学习的跨被试前额叶EEG风险感知预测
# 适配目标域数据格式：CSV文件按被试文件夹组织，包含EEG信号和风险得分列

# %% [code] 安装依赖
!pip install mne torchmeta pytorch-lightning captum scikit-learn umap-learn pandas

# %% [code] 导入库
import os
import glob
import numpy as np
import pandas as pd
import mne
import torch
import torch.nn as nn
import torch.optim as optim
from torchmeta.utils.gradient_based import reptile_update
import torchmeta as tm
import pytorch_lightning as pl
from pytorch_lightning.callbacks import EarlyStopping
from captum.attr import IntegratedGradients
from sklearn.model_selection import LeaveOneGroupOut
from sklearn.metrics import roc_auc_score, f1_score
from umap import UMAP
import matplotlib.pyplot as plt
from tqdm import tqdm
import re

# %% [code] 配置参数
class Config:
    # 数据参数
    seed_vig_path = "./data/SEED-VIG"  # 预训练数据集路径
    target_data_root = "./data/driving_risk"  # 目标域数据根目录
    risk_score_file = "./data/risk_scores.csv"  # 风险得分文件
    fs = 500  # 原始采样率
    target_fs = 250  # 降采样后的采样率
    bands = {'delta': (1, 4), 'theta': (4, 8), 'alpha': (8, 14), 
             'beta': (14, 31), 'gamma': (31, 50)}
    
    # 模型参数
    input_channels = 5  # 5个频带
    hidden_dim = 32
    num_classes = 2
    
    # 训练参数
    pretrain_epochs = 20
    meta_epochs = 100
    n_way = 1  # 每次任务类别数
    k_shot = 5  # 支持集样本数
    meta_batch_size = 4  # 每次元更新的任务数
    lr = 1e-4
    use_augmentation = True  # 是否使用数据增强
    
    # 硬件优化
    batch_size = 32
    precision = '16-mixed'  # 混合精度训练
    accelerator = 'auto'
    
config = Config()

# %% [code] 数据预处理函数 - 适配CSV格式
class EEGPreprocessor:
    def __init__(self, config):
        self.config = config
        self.ch_names = ['FP1']  # 单通道前额叶
        
    def process_seed_vig(self, file_path):
        """处理SEED-VIG数据集用于预训练"""
        # 加载数据 (假设为fif格式)
        raw = mne.io.read_raw_fif(file_path, preload=True)
        
        # 预处理流程
        raw = self._preprocess_raw(raw)
        
        # 提取特征
        features, labels = self.extract_features(raw)
        return features, labels
    
    def process_driving_data(self, csv_path, scenario_duration=240):
        """
        处理目标域驾驶风险数据CSV文件
        csv_path: CSV文件路径
        scenario_duration: 场景持续时间(秒)
        """
        # 读取CSV数据
        df = pd.read_csv(csv_path)
        
        # 检查必需的列
        if 'FP1' not in df.columns:
            raise ValueError("CSV文件必须包含'FP1'列作为EEG信号")
            
        # 创建MNE原始对象
        eeg_data = df['FP1'].values.reshape(1, -1) * 1e-6  # 转换为伏特
        info = mne.create_info(
            ch_names=['FP1'],
            sfreq=self.config.fs,
            ch_types=['eeg']
        )
        raw = mne.io.RawArray(eeg_data, info)
        
        # 预处理流程
        raw = self._preprocess_raw(raw)
        
        # 提取特征 - 整个场景作为单个样本
        features = self.extract_features(raw, is_target=True, duration=scenario_duration)
        return features
    
    def _preprocess_raw(self, raw):
        """通用预处理流程"""
        # 降采样
        if raw.info['sfreq'] > self.config.target_fs:
            raw.resample(self.config.target_fs, npad='auto')
        
        # 带通滤波
        raw.filter(1, 50, fir_design='firwin')
        
        # 选择前额叶通道
        picks = mne.pick_channels(raw.ch_names, include=self.ch_names)
        raw.pick_channels([raw.ch_names[i] for i in picks])
        return raw
    
    def extract_features(self, raw, is_target=False, duration=4.0):
        """
        提取5频带差分熵特征
        duration: 分段时长(秒)
        """
        # 创建固定长度epoch
        epochs = mne.make_fixed_length_epochs(raw, duration=duration, overlap=duration/2)
        
        # 计算功率谱密度
        psd, freqs = mne.time_frequency.psd_multitaper(
            epochs, fmin=1, fmax=50, bandwidth=1)
        
        # 计算频带平均PSD
        band_psd = []
        for band, (fmin, fmax) in self.config.bands.items():
            freq_mask = (freqs >= fmin) & (freqs <= fmax)
            band_psd.append(psd[:, :, freq_mask].mean(axis=-1))
        
        # 差分熵特征 = log(PSD)
        de_features = np.log(np.array(band_psd).transpose(1, 2, 0))
        
        # 对于目标数据，返回每个epoch的特征
        if is_target:
            return de_features.squeeze(1)  # [n_epochs, 5]
        
        # 对于SEED-VIG，返回特征和标签（示例）
        labels = np.random.randint(0, 3, len(de_features))  # 示例：警觉度标签
        return de_features.squeeze(1), labels

# %% [code] 数据加载器 - 适配文件夹结构
def load_target_data(config):
    """
    加载目标域数据并处理
    返回:
        features: 特征数组 [n_samples, n_features]
        labels: 标签数组 [n_samples]
        subject_ids: 被试ID数组 [n_samples]
        scenario_ids: 场景ID数组 [n_samples]
    """
    # 加载风险得分
    risk_scores = pd.read_csv(config.risk_score_file)
    risk_scores['subject_id'] = risk_scores['subject_id'].astype(str)
    
    # 初始化
    all_features = []
    all_labels = []
    all_subjects = []
    all_scenarios = []
    
    preprocessor = EEGPreprocessor(config)
    
    # 遍历所有被试文件夹
    subject_folders = glob.glob(os.path.join(config.target_data_root, "sub_*"))
    print(f"Found {len(subject_folders)} subject folders")
    
    for subject_folder in tqdm(subject_folders, desc="Processing subjects"):
        # 提取被试ID
        subject_id = os.path.basename(subject_folder).split("_")[1]
        
        # 查找该被试的所有场景文件
        scenario_files = glob.glob(os.path.join(subject_folder, f"{subject_id}_*.csv"))
        
        for scenario_file in scenario_files:
            # 提取场景ID
            scenario_id = re.search(rf"{subject_id}_(\d+)\.csv", os.path.basename(scenario_file)).group(1)
            
            # 获取风险得分
            scenario_score = risk_scores[
                (risk_scores['subject_id'] == subject_id) & 
                (risk_scores['scenario_id'] == int(scenario_id))
            ]
            
            if len(scenario_score) == 0:
                print(f"Warning: No risk score for subject {subject_id}, scenario {scenario_id}")
                continue
                
            risk_total = scenario_score['Risk_Total'].values[0]
            
            # 处理EEG数据
            try:
                features = preprocessor.process_driving_data(scenario_file)
                n_samples = features.shape[0]
                
                # 添加数据
                all_features.append(features)
                all_labels.extend([risk_total] * n_samples)
                all_subjects.extend([subject_id] * n_samples)
                all_scenarios.extend([scenario_id] * n_samples)
            except Exception as e:
                print(f"Error processing {scenario_file}: {str(e)}")
    
    # 合并所有数据
    if len(all_features) == 0:
        raise ValueError("No valid data found!")
    
    features_array = np.concatenate(all_features)
    labels_array = np.array(all_labels)
    subject_array = np.array(all_subjects)
    scenario_array = np.array(all_scenarios)
    
    # 二值化标签
    median_risk = np.median(labels_array)
    binary_labels = (labels_array > median_risk).astype(int)
    
    print(f"Loaded data: {features_array.shape[0]} samples from {len(np.unique(subject_array))} subjects")
    return features_array, binary_labels, subject_array, scenario_array

# %% [code] 数据增强类 (保持不变)
class EEGAugmentor:
    def __init__(self, noise_level=0.05):
        self.noise_level = noise_level
        
    def augment(self, features):
        """应用多种数据增强"""
        # 随机选择增强方式
        augment_type = np.random.choice(['noise', 'warp', 'mask'])
        
        if augment_type == 'noise':
            return self.add_gaussian_noise(features)
        elif augment_type == 'warp':
            return self.time_warp(features)
        else:
            return self.freq_band_mask(features)
    
    def add_gaussian_noise(self, features):
        noise = np.random.normal(0, self.noise_level, features.shape)
        return features + noise
    
    def time_warp(self, features):
        warp_factor = np.random.uniform(0.8, 1.2)
        warped = np.zeros_like(features)
        for i in range(features.shape[1]):  # 每个频带
            warped[:, i] = np.interp(
                np.linspace(0, features.shape[0]-1, int(features.shape[0]*warp_factor)),
                np.arange(features.shape[0]),
                features[:, i]
            )[:features.shape[0]]
        return warped
    
    def freq_band_mask(self, features):
        mask = np.random.binomial(1, 0.8, (features.shape[1],))
        return features * mask

# %% [code] 元学习模型定义 (保持不变)
class MetaFPNet(tm.Module):
    def __init__(self, in_channels, hidden_dim, num_classes):
        super().__init__()
        # 时频特征提取器 (参数量<5K)
        self.feature_extractor = nn.Sequential(
            nn.Conv1d(in_channels, 16, kernel_size=5, padding=2),
            nn.BatchNorm1d(16),
            nn.ELU(),
            nn.Conv1d(16, hidden_dim, kernel_size=3, stride=2),
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten()
        )
        
        # 元自适应分类器
        self.classifier = tm.Linear(hidden_dim, num_classes)
        
        # 神经科学注意力（频带权重）
        self.band_attn = nn.Parameter(torch.tensor([0.1, 0.2, 0.3, 0.2, 0.2]))
    
    def forward(self, x, params=None):
        # 频带注意力加权
        x = x * self.band_attn.unsqueeze(0).unsqueeze(-1)
        
        # 特征提取
        x = self.feature_extractor(x)
        
        # 元学习分类
        return self.classifier(x, params=self.get_subdict(params, 'classifier'))

# %% [code] 元学习训练模块 (保持不变)
class MetaLearner(pl.LightningModule):
    def __init__(self, model, config):
        super().__init__()
        self.model = model
        self.config = config
        self.loss_fn = nn.CrossEntropyLoss()
        
        # 神经科学正则化权重
        self.reg_weights = {
            'rrc': 0.3,  # 风险响应约束
            'contrast': 0.2  # 场景对比
        }
    
    def training_step(self, batch, batch_idx):
        # 元学习批处理：多个任务
        task_losses = []
        for task_batch in batch:
            # 每个任务包含支持集和查询集
            support_data, support_labels = task_batch['support']
            query_data, query_labels = task_batch['query']
            
            # 克隆模型用于任务适应
            learner = self.model.clone()
            
            # 在支持集上快速适应
            support_outputs = learner(support_data)
            support_loss = self.loss_fn(support_outputs, support_labels)
            learner.adapt(support_loss)
            
            # 查询集评估
            query_outputs = learner(query_data)
            query_loss = self.loss_fn(query_outputs, query_labels)
            
            # 应用神经科学正则化
            features = learner.feature_extractor(query_data)
            reg_loss = self._neuroscience_regularization(features, query_labels)
            
            task_loss = query_loss + reg_loss
            task_losses.append(task_loss)
        
        # 元更新
        meta_loss = torch.stack(task_losses).mean()
        self.log('train_meta_loss', meta_loss)
        return meta_loss
    
    def _neuroscience_regularization(self, features, labels):
        """神经科学启发的正则化项"""
        # 1. 风险响应约束（高风险样本激活更强）
        high_risk_mask = (labels == 1)
        if torch.sum(high_risk_mask) > 0:
            high_risk_act = features[high_risk_mask].mean()
            low_risk_act = features[~high_risk_mask].mean()
            rrc_loss = torch.relu(0.3 - (high_risk_act - low_risk_act))
        else:
            rrc_loss = torch.tensor(0.0)
        
        # 2. 场景对比学习（需要场景标签）
        # 实际实现中需要获取场景信息
        contrast_loss = torch.tensor(0.0)
        
        total_reg = self.reg_weights['rrc'] * rrc_loss + \
                    self.reg_weights['contrast'] * contrast_loss
        return total_reg
    
    def configure_optimizers(self):
        return optim.AdamW(self.parameters(), lr=self.config.lr)

# %% [code] 数据加载器 - 适配新格式
def create_meta_learning_dataloader(data, labels, subject_ids, k_shot=5, n_query=3, augmentor=None):
    """
    为元学习创建任务数据加载器
    每个任务对应一个被试
    """
    unique_subjects = np.unique(subject_ids)
    tasks = []
    
    for subj_id in unique_subjects:
        # 获取当前被试的所有数据
        subj_mask = (subject_ids == subj_id)
        subj_data = data[subj_mask]
        subj_labels = labels[subj_mask]
        
        # 随机选择支持集和查询集
        n_samples = len(subj_data)
        if n_samples < (k_shot + n_query):
            print(f"Subject {subj_id} has only {n_samples} samples, skipping")
            continue
            
        indices = np.random.permutation(n_samples)
        support_idx = indices[:k_shot]
        query_idx = indices[k_shot:k_shot+n_query]
        
        # 支持集数据增强
        support_data = []
        for idx in support_idx:
            sample = subj_data[idx]
            if augmentor:
                sample = augmentor.augment(sample)
            support_data.append(sample)
        support_data = np.array(support_data)
        
        # 查询集数据增强
        query_data = []
        for idx in query_idx:
            sample = subj_data[idx]
            if augmentor:
                sample = augmentor.augment(sample)
            query_data.append(sample)
        query_data = np.array(query_data)
        
        # 转换为张量
        support_data = torch.tensor(support_data, dtype=torch.float32)
        support_labels = torch.tensor(subj_labels[support_idx], dtype=torch.long)
        query_data = torch.tensor(query_data, dtype=torch.float32)
        query_labels = torch.tensor(subj_labels[query_idx], dtype=torch.long)
        
        tasks.append({
            'support': (support_data, support_labels),
            'query': (query_data, query_labels)
        })
    
    print(f"Created {len(tasks)} meta-learning tasks")
    return tasks

# %% [code] 模型训练流程 - 更新数据加载
def train_pipeline(config):
    # 1. 初始化组件
    preprocessor = EEGPreprocessor(config)
    augmentor = EEGAugmentor() if config.use_augmentation else None
    
    # 2. 加载并预处理SEED-VIG数据
    print("Processing SEED-VIG data for pretraining...")
    seed_vig_data, seed_vig_labels = [], []
    for file in tqdm(os.listdir(config.seed_vig_path)):
        if file.endswith('.fif'):
            data, labels = preprocessor.process_seed_vig(
                os.path.join(config.seed_vig_path, file))
            seed_vig_data.append(data)
            seed_vig_labels.append(labels)
    
    # 如果没有SEED-VIG数据，使用随机数据
    if len(seed_vig_data) == 0:
        print("Warning: No SEED-VIG data found, using random data for pretraining")
        seed_vig_data = np.random.randn(1000, 5).astype(np.float32)
        seed_vig_labels = np.random.randint(0, 3, 1000)
    else:
        seed_vig_data = np.concatenate(seed_vig_data)
        seed_vig_labels = np.concatenate(seed_vig_labels)
    
    # 3. 加载目标域数据
    print("Processing driving risk data...")
    risk_data, risk_labels, subject_ids, scenario_ids = load_target_data(config)
    
    # 4. 创建元学习数据加载器
    print("Creating meta-learning tasks...")
    meta_tasks = create_meta_learning_dataloader(
        risk_data, risk_labels, subject_ids, 
        k_shot=config.k_shot, n_query=3, augmentor=augmentor)
    
    # 如果没有任务创建，使用随机任务
    if len(meta_tasks) == 0:
        print("Warning: No meta tasks created, using random tasks")
        meta_tasks = []
        for _ in range(20):
            support_data = torch.randn(config.k_shot, 5)
            support_labels = torch.randint(0, 2, (config.k_shot,))
            query_data = torch.randn(3, 5)
            query_labels = torch.randint(0, 2, (3,))
            meta_tasks.append({
                'support': (support_data, support_labels),
                'query': (query_data, query_labels)
            })
    
    # 5. 初始化模型
    model = MetaFPNet(config.input_channels, config.hidden_dim, config.num_classes)
    
    # 6. 预训练阶段（SEED-VIG）
    print("Starting pretraining on SEED-VIG...")
    # 转换为PyTorch数据集
    class SeedVigDataset(torch.utils.data.Dataset):
        def __init__(self, data, labels):
            self.data = torch.tensor(data, dtype=torch.float32)
            self.labels = torch.tensor(labels, dtype=torch.long)
            
        def __len__(self):
            return len(self.data)
            
        def __getitem__(self, idx):
            return self.data[idx], self.labels[idx]
    
    seed_vig_dataset = SeedVigDataset(seed_vig_data, seed_vig_labels)
    seed_vig_loader = torch.utils.data.DataLoader(
        seed_vig_dataset, batch_size=config.batch_size, shuffle=True)
    
    # 预训练模型
    pretrain_model = model
    pretrain_optimizer = optim.Adam(pretrain_model.parameters(), lr=config.lr)
    
    for epoch in tqdm(range(config.pretrain_epochs), desc="Pretraining"):
        pretrain_model.train()
        for batch_data, batch_labels in seed_vig_loader:
            pretrain_optimizer.zero_grad()
            outputs = pretrain_model(batch_data)
            loss = nn.CrossEntropyLoss()(outputs, batch_labels)
            loss.backward()
            pretrain_optimizer.step()
    
    # 7. 元学习微调
    print("Starting meta-learning fine-tuning...")
    meta_learner = MetaLearner(model, config)
    meta_optimizer = meta_learner.configure_optimizers()
    
    # 元训练循环
    for epoch in tqdm(range(config.meta_epochs), desc="Meta-Learning"):
        # 随机选择一批任务
        batch_tasks = np.random.choice(meta_tasks, config.meta_batch_size, replace=False)
        
        # 清空梯度
        meta_optimizer.zero_grad()
        
        # 计算元梯度
        task_losses = []
        for task in batch_tasks:
            support_data, support_labels = task['support']
            query_data, query_labels = task['query']
            
            # 克隆模型用于任务适应
            learner = model.clone()
            
            # 在支持集上快速适应
            support_outputs = learner(support_data)
            support_loss = nn.CrossEntropyLoss()(support_outputs, support_labels)
            learner.adapt(support_loss)
            
            # 查询集评估
            query_outputs = learner(query_data)
            query_loss = nn.CrossEntropyLoss()(query_outputs, query_labels)
            task_losses.append(query_loss)
        
        # 元更新
        meta_loss = torch.mean(torch.stack(task_losses))
        meta_loss.backward()
        meta_optimizer.step()
        
        # 记录损失
        if epoch % 10 == 0:
            print(f"Epoch {epoch}/{config.meta_epochs}, Meta Loss: {meta_loss.item():.4f}")
    
    print("Training complete! Saving model...")
    torch.save(model.state_dict(), "meta_fpnet_final.pth")
    return model

# %% [code] 评估与可视化
def evaluate_model(model, test_data, test_labels, subject_ids):
    """跨被试留一验证评估"""
    logo = LeaveOneGroupOut()
    all_preds = []
    all_targets = []
    
    # 获取唯一被试
    unique_subjects = np.unique(subject_ids)
    
    for test_subject in tqdm(unique_subjects, desc="Cross-subject Evaluation"):
        # 划分训练测试集
        train_mask = (subject_ids != test_subject)
        test_mask = (subject_ids == test_subject)
        
        X_train = test_data[train_mask]
        y_train = test_labels[train_mask]
        X_test = test_data[test_mask]
        y_test = test_labels[test_mask]
        
        # 转换为张量
        X_train = torch.tensor(X_train, dtype=torch.float32)
        y_train = torch.tensor(y_train, dtype=torch.long)
        X_test = torch.tensor(X_test, dtype=torch.float32)
        y_test = torch.tensor(y_test, dtype=torch.long)
        
        # 克隆模型用于适应
        adapted_model = model.clone()
        optimizer = optim.SGD(adapted_model.parameters(), lr=0.01)
        
        # 快速适应（少量步骤）
        for _ in range(5):
            outputs = adapted_model(X_train)
            loss = nn.CrossEntropyLoss()(outputs, y_train)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
        
        # 在测试集上评估
        with torch.no_grad():
            test_outputs = adapted_model(X_test)
            preds = torch.softmax(test_outputs, dim=1)[:, 1]
        
        all_preds.extend(preds.cpu().numpy())
        all_targets.extend(y_test.cpu().numpy())
    
    # 计算指标
    auc = roc_auc_score(all_targets, all_preds)
    pred_labels = (np.array(all_preds) > 0.5).astype(int)
    f1 = f1_score(all_targets, pred_labels)
    acc = np.mean(pred_labels == all_targets)
    
    print(f"Cross-subject Evaluation Results:")
    print(f"- Subjects: {len(unique_subjects)}")
    print(f"- AUC: {auc:.4f}")
    print(f"- F1: {f1:.4f}")
    print(f"- Accuracy: {acc:.4f}")
    
    return auc, f1, acc

def visualize_band_importance(model, sample_data):
    """可视化频带重要性"""
    # 确保模型在评估模式
    model.eval()
    
    # 创建Integrated Gradients对象
    ig = IntegratedGradients(model)
    
    # 计算归因
    attributions = ig.attribute(
        sample_data, 
        target=1,  # 高风险类别
        n_steps=50
    )
    
    # 计算频带平均重要性
    band_importance = attributions.mean(dim=(0, 2)).detach().cpu().numpy()
    
    # 绘图
    plt.figure(figsize=(10, 6))
    bands = list(config.bands.keys())
    plt.bar(bands, band_importance)
    plt.title("EEG Band Importance for Risk Prediction")
    plt.ylabel("Attribution Score")
    plt.xticks(rotation=45)
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.tight_layout()
    plt.savefig("band_importance.png")
    plt.show()
    
    return band_importance

def visualize_feature_space(model, data, labels, subject_ids):
    """可视化特征空间"""
    # 提取特征
    features = []
    model.eval()
    
    # 分批处理避免内存溢出
    for i in tqdm(range(0, len(data), config.batch_size), desc="Extracting features"):
        batch_data = data[i:i+config.batch_size]
        batch_tensor = torch.tensor(batch_data, dtype=torch.float32)
        
        with torch.no_grad():
            feat = model.feature_extractor(batch_tensor).cpu().numpy()
            features.append(feat)
    
    features = np.concatenate(features)
    
    # UMAP降维
    print("Running UMAP dimensionality reduction...")
    reducer = UMAP(n_components=2, random_state=42)
    embeddings = reducer.fit_transform(features)
    
    # 按风险级别绘图
    plt.figure(figsize=(12, 8))
    low_risk_idx = (labels == 0)
    high_risk_idx = (labels == 1)
    
    plt.scatter(
        embeddings[low_risk_idx, 0], embeddings[low_risk_idx, 1],
        c='blue', alpha=0.5, label='Low Risk', s=20
    )
    plt.scatter(
        embeddings[high_risk_idx, 0], embeddings[high_risk_idx, 1],
        c='red', alpha=0.5, label='High Risk', s=20
    )
    
    plt.title("EEG Feature Space Visualization by Risk Level")
    plt.xlabel("UMAP Dimension 1")
    plt.ylabel("UMAP Dimension 2")
    plt.legend()
    plt.grid(alpha=0.2)
    plt.tight_layout()
    plt.savefig("feature_space_risk.png")
    plt.show()
    
    # 按被试绘图
    unique_subjects = np.unique(subject_ids)
    plt.figure(figsize=(14, 10))
    for i, subj_id in enumerate(unique_subjects[:20]):  # 最多显示20个被试
        subj_mask = (subject_ids == subj_id)
        plt.scatter(
            embeddings[subj_mask, 0], embeddings[subj_mask, 1],
            label=f"Subj {subj_id}", alpha=0.7, s=30
        )
    
    plt.title("EEG Feature Space Visualization by Subject")
    plt.xlabel("UMAP Dimension 1")
    plt.ylabel("UMAP Dimension 2")
    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))
    plt.grid(alpha=0.2)
    plt.tight_layout()
    plt.savefig("feature_space_subject.png")
    plt.show()
    
    return embeddings

# %% [code] 主执行流程
if __name__ == "__main__":
    # 训练模型
    print("Starting training pipeline...")
    trained_model = train_pipeline(config)
    
    # 加载测试数据（使用完整数据集）
    print("Loading data for evaluation...")
    test_data, test_labels, test_subjects, _ = load_target_data(config)
    
    # 评估模型
    print("Evaluating model...")
    auc, f1, acc = evaluate_model(trained_model, test_data, test_labels, test_subjects)
    
    # 可视化分析
    print("Running visualizations...")
    sample_idx = np.random.choice(len(test_data), min(32, len(test_data)), replace=False)
    sample_data = torch.tensor(test_data[sample_idx], dtype=torch.float32)
    band_importance = visualize_band_importance(trained_model, sample_data)
    
    # 特征空间可视化
    embeddings = visualize_feature_space(trained_model, test_data, test_labels, test_subjects)
    
    print("\n=== Final Results ===")
    print(f"- Cross-subject AUC: {auc:.4f}")
    print(f"- F1 Score: {f1:.4f}")
    print(f"- Accuracy: {acc:.4f}")
    print(f"- Band Importance: {dict(zip(config.bands.keys(), band_importance))}")
    print("\nAll tasks completed!")
